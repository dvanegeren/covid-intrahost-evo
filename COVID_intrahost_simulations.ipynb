{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import time\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from scipy import stats\n",
    "import scipy.optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulation functions\n",
    "def update(state, fitness, next_gen, burst_size, mut_prob):\n",
    "    num_replicating = math.ceil(next_gen/burst_size)\n",
    "    rep_probs = np.multiply(state, fitness)\n",
    "    rep_probs = rep_probs/np.sum(rep_probs)\n",
    "    rep_viruses = np.random.choice(len(fitness), size=num_replicating, replace=True, p=rep_probs)\n",
    "    unique, counts = np.unique(rep_viruses, return_counts=True)\n",
    "\n",
    "    to_select, select_probs = np.unique(rep_viruses, return_counts=True)\n",
    "    survivors = np.random.choice(to_select, size=int(next_gen), replace=True, p=select_probs/np.sum(select_probs))\n",
    "    \n",
    "    unique, counts = np.unique(survivors, return_counts=True)\n",
    "    mutators = np.random.choice(survivors, size=np.random.binomial(next_gen, mut_prob), replace=False)\n",
    "    \n",
    "    unique, counts = np.unique(mutators, return_counts=True)\n",
    "    to_return = []\n",
    "    for i in range(len(fitness)):\n",
    "        new_pop = np.sum(survivors == i)\n",
    "        new_pop += np.sum(mutators == (i-1))\n",
    "        new_pop -= np.sum(mutators == i)\n",
    "        to_return.append(new_pop)\n",
    "    return(np.array(to_return))\n",
    "\n",
    "def simulate(viral_load_curve, fitness_cost, fitness_benefit, num_mut, mut_prob, burst_size=1e3):\n",
    "    fitnesses = np.zeros(num_mut+1) + 1\n",
    "    if num_mut > 1:\n",
    "        fitnesses[1:(num_mut-1)] -= fitness_cost\n",
    "    fitnesses[-1] += fitness_benefit\n",
    "    curr_state = np.zeros(num_mut+1)\n",
    "    curr_state[0] = viral_load_curve[0]\n",
    "    all_data = np.zeros((len(viral_load_curve), num_mut+1))\n",
    "    all_data[0,:] = curr_state\n",
    "    for i in range(1,len(viral_load_curve)):\n",
    "        load = viral_load_curve[i]\n",
    "        curr_state = update(curr_state, fitnesses, load, burst_size, mut_prob)\n",
    "        all_data[i,:] = curr_state\n",
    "    return(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for processing and plotting simulation data\n",
    "def compute_fracs(data, log_data=True, CI=None, median=False):\n",
    "    all_data = np.array(data)\n",
    "    \n",
    "    kinetics = np.sum(data[0], axis=1)\n",
    "    kinetics = np.reshape(kinetics, (len(kinetics),1))\n",
    "    all_data = all_data/kinetics\n",
    "    if log_data:\n",
    "        all_data = np.log10(all_data)\n",
    "        all_data[all_data == -np.inf] = -7\n",
    "    \n",
    "    if median:\n",
    "        means = np.quantile(all_data, 0.5, axis=0)\n",
    "    else:\n",
    "        means = np.nanmean(all_data, axis=0)\n",
    "    if CI is None:\n",
    "        sem = stats.sem(means, nan_policy=\"omit\")\n",
    "        lowers = means - sem\n",
    "        uppers = means + sem\n",
    "    else:\n",
    "        lowers = np.quantile(all_data, (1-CI)/2, axis=0)\n",
    "        uppers = np.quantile(all_data, 1-(1-CI)/2, axis=0)\n",
    "    return([means, lowers, uppers])\n",
    "\n",
    "def transmit_probs(data, end_time=None, num_trans=100):\n",
    "    all_data = np.array(data)\n",
    "    \n",
    "    if not end_time is None:\n",
    "        all_data = all_data[:,0:int(end_time*2),:]\n",
    "    total_load = np.sum(all_data[0,:,:])\n",
    "    \n",
    "    pt_probs = np.sum(all_data, axis=1)/total_load\n",
    "    pt_probs = 1-np.power((1-pt_probs), num_trans)\n",
    "    \n",
    "    return(pt_probs)\n",
    "\n",
    "def max_freq(data):\n",
    "    all_data = np.array(data)\n",
    "    \n",
    "    kinetics = np.sum(data[0], axis=1)\n",
    "    kinetics = np.reshape(kinetics, (len(kinetics),1))\n",
    "    all_data = all_data/kinetics\n",
    "\n",
    "    maxes = np.quantile(all_data, 1, axis=1)\n",
    "    return(np.mean(maxes, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7734137/\n",
    "\n",
    "long_lower_IQR = 86\n",
    "long_upper_IQR = 101.5\n",
    "est_SD = (long_upper_IQR-long_lower_IQR)/1.35\n",
    "est_mean = (long_upper_IQR+long_lower_IQR)/2\n",
    "\n",
    "from scipy.stats import norm\n",
    "total_lens = np.array(extra_weeks) * 7 + 23-5\n",
    "cdf_vals = norm.cdf(total_lens, loc=est_mean, scale=est_SD)\n",
    "long_dist = cdf_vals[1:] - cdf_vals[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulations for Figure 1C-E\n",
    "viral_load_kinetics = [1000, 1e3, 1e5, 1e5, 1e6, 1e6, 1e6, 1e7, 1e7, 1e7, 1e8, 1e8, 1e9, 1e9, 1e9, 1e9, 1e8, 1e8, 1e8, 1e8, 1e7, 1e7, 1e7, 1e7, 1e6, 1e6, 1e6, 1e6, 1e6, 1e6, 1e6, 1e6, 1e5, 1e5, 1e5, 1e5, 1e5, 1e5, 1e5, 1e5, 1e5, 1e5, 1e4, 1e4, 1e4, 1e3]\n",
    "fitness_benefits = [-0.01, -0.05, 0, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "viral_load_kinetics = [1000, 1e3, 1e5, 1e5, 1e6, 1e6, 1e6, 1e7, 1e7, 1e7, 1e8, 1e8, 1e9, 1e9, 1e9, 1e9, 1e8, 1e8, 1e8, 1e8, 1e7, 1e7, 1e7, 1e7, 1e6, 1e6, 1e6, 1e6, 1e6, 1e6, 1e6, 1e6, 1e5, 1e5, 1e5, 1e5, 1e5, 1e5, 1e5, 1e5, 1e5, 1e5, 1e4, 1e4, 1e4, 1e3]\n",
    "viral_load_adj = np.array(viral_load_kinetics)/1000\n",
    "\n",
    "num_iter = 1000\n",
    "\n",
    "for benefit in fitness_benefits:\n",
    "    print(benefit)\n",
    "    all_res = []\n",
    "    for i in range(num_iter):\n",
    "        all_res.append(simulate(viral_load_adj, None, benefit, 1, 1e-5, burst_size=1))\n",
    "    pickle.dump(all_res, open(\"./results/standard_\"+str(benefit)+\".p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading for Figure 1C-E\n",
    "fitness_benefits = [-0.05, -0.01, 0, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "\n",
    "means = []\n",
    "lowers = []\n",
    "uppers = []\n",
    "early_probs = []\n",
    "mid_probs = []\n",
    "midlate_probs = []\n",
    "late_probs = []\n",
    "for benefit in fitness_benefits:\n",
    "    data = pickle.load(open(\"./results/standard_\"+str(benefit)+\".p\", \"rb\" ))\n",
    "    mean, lower, upper = compute_fracs(data, log_data=False, CI=None, median=False)\n",
    "    means.append(mean)\n",
    "    lowers.append(lower)\n",
    "    uppers.append(upper)\n",
    "    early_probs.append(transmit_probs(data, 3, num_trans=10))\n",
    "    mid_probs.append(transmit_probs(data, 5, num_trans=10))\n",
    "    midlate_probs.append(transmit_probs(data, 7, num_trans=10))\n",
    "    late_probs.append(transmit_probs(data, 23, num_trans=10))\n",
    "    \n",
    "to_plot = pd.DataFrame({\"benefit\":fitness_benefits, \"day3\":[np.mean(x[:,1]) for x in early_probs], \"day5\":[np.mean(x[:,1]) for x in mid_probs], \"day7\":[np.mean(x[:,1]) for x in midlate_probs], 'any':[np.mean(x[:,1]) for x in late_probs]})\n",
    "prob_SEMs = pd.DataFrame({\"benefit\":fitness_benefits, \"day3\":[stats.sem(x[:,1]) for x in early_probs], \"day5\":[stats.sem(x[:,1]) for x in mid_probs], \"day7\":[stats.sem(x[:,1]) for x in midlate_probs], 'any':[stats.sem(x[:,1]) for x in late_probs]})\n",
    "to_plot.sort_values(by=\"benefit\", inplace=True)\n",
    "prob_SEMs.sort_values(by=\"benefit\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting Fig. 1C\n",
    "N_color = LinearSegmentedColormap.from_list(colors=[\"purple\", \"cyan\"], name=\"N\")\n",
    "\n",
    "xplot = np.arange(np.shape(data[0])[0])/2\n",
    "mut_index = 1\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "for i in range(len(fitness_benefits)):\n",
    "    plt.plot(xplot, means[i][:,mut_index], color=N_color((fitness_benefits[i]+0.05)/.55))\n",
    "    plt.fill_between(xplot, lowers[i][:,mut_index], uppers[i][:,mut_index], color=N_color((fitness_benefits[i]+0.05)/.55), alpha=0.3)\n",
    "    \n",
    "#plt.yscale(\"log\")\n",
    "plt.ylabel(\"mean intrahost\\nfrequency of variant\", fontsize=14)\n",
    "plt.xlabel(\"days since infection\", fontsize=14)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\".pdf\", transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting Fig. 1D\n",
    "plt.figure()\n",
    "plt.plot(to_plot[\"benefit\"], to_plot[\"day3\"], color=\"lightcoral\")\n",
    "plt.fill_between(to_plot[\"benefit\"], to_plot[\"day3\"]-prob_SEMs[\"day3\"], to_plot[\"day3\"]+prob_SEMs[\"day3\"], color=\"lightcoral\", alpha=0.1)\n",
    "plt.plot(to_plot[\"benefit\"], to_plot[\"day5\"], color=\"indianred\")\n",
    "plt.fill_between(to_plot[\"benefit\"], to_plot[\"day5\"]-prob_SEMs[\"day5\"], to_plot[\"day5\"]+prob_SEMs[\"day5\"], color=\"indianred\", alpha=0.1)\n",
    "plt.plot(to_plot[\"benefit\"], to_plot[\"day7\"], color=\"firebrick\")\n",
    "plt.fill_between(to_plot[\"benefit\"], to_plot[\"day7\"]-prob_SEMs[\"day7\"], to_plot[\"day7\"]+prob_SEMs[\"day7\"], color=\"firebrick\", alpha=0.1)\n",
    "plt.plot(to_plot[\"benefit\"], to_plot[\"any\"], color=\"maroon\")\n",
    "plt.fill_between(to_plot[\"benefit\"], to_plot[\"any\"]-prob_SEMs[\"any\"], to_plot[\"any\"]+prob_SEMs[\"any\"], color=\"maroon\", alpha=0.1)\n",
    "plt.ylabel(\"probability of passing on variant\", fontsize=14)\n",
    "plt.xlabel(\"fitness effect of mutation\", fontsize=14)\n",
    "#plt.yscale(\"log\")\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\".pdf\", transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting Fig. 1E\n",
    "N = 5e4\n",
    "l = 14\n",
    "\n",
    "lams = [1.1, 1.2, 1.3, 1.4, 1.5]\n",
    "est_prob = []\n",
    "\n",
    "for lam in lams:\n",
    "    def find_pext(x):\n",
    "        return(1-np.exp(-lam*x) - x)\n",
    "    p_surv = scipy.optimize.broyden1(find_pext, 0.1, f_tol=1e-14)\n",
    "    est_prob.append(to_plot[\"day7\"]*p_surv*N)\n",
    "\n",
    "plt.figure()\n",
    "sns.heatmap(est_prob, cmap=\"Reds\").invert_yaxis()\n",
    "plt.ylabel(\"$R_0$ of new mutant\", fontsize=14)\n",
    "plt.xlabel(\"fitness effect of mutation\", fontsize=14)\n",
    "#plt.yscale(\"log\")\n",
    "plt.xticks(ticks=np.arange(10) + 0.5, labels=fitness_benefits, fontsize=12)\n",
    "plt.yticks(ticks=np.arange(5) + 0.5, labels=lams, fontsize=12)\n",
    "#sns.despine()\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\".eps\", transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulations for Fig. 2A\n",
    "left_kinetics = [1000, 1e3, 1e5, 1e5, 1e6, 1e6, 1e6, 1e7, 1e7, 1e7, 1e8, 1e8]\n",
    "right_kinetics = [1e9, 1e9, 1e9, 1e9, 1e8, 1e8, 1e8, 1e8, 1e7, 1e7, 1e7, 1e7, 1e6, 1e6, 1e6, 1e6, 1e6, 1e6, 1e6, 1e6, 1e5, 1e5, 1e5, 1e5, 1e5, 1e5, 1e5, 1e5, 1e5, 1e5, 1e4, 1e4, 1e4, 1e3]\n",
    "extra_days = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "benefit = 0.2\n",
    "\n",
    "num_iter = 1000\n",
    "\n",
    "for time in extra_days:\n",
    "    print(time)\n",
    "    all_res = []\n",
    "    new_viral_load = left_kinetics + [1e9]*(time*2) + right_kinetics\n",
    "    new_viral_load = np.array(new_viral_load)/1000\n",
    "    for i in range(num_iter):\n",
    "        all_res.append(simulate(new_viral_load, None, benefit, 1, 1e-5, burst_size=1))\n",
    "    pickle.dump(all_res, open(\"./results/single_long_\"+str(time)+\".p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting Fig. 2A\n",
    "extra_days = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "means = []\n",
    "lowers = []\n",
    "uppers = []\n",
    "trans_probs = []\n",
    "for week in extra_days:\n",
    "    data = pickle.load(open(\"./results/single_long_\"+str(week)+\".p\", \"rb\" ))\n",
    "    mean, lower, upper = compute_fracs(data, log_data=False, CI=None, median=False)\n",
    "    means.append(mean)\n",
    "    lowers.append(lower)\n",
    "    uppers.append(upper)\n",
    "    trans_probs.append(transmit_probs(data))\n",
    "    \n",
    "to_plot = pd.DataFrame({\"days\":extra_days, 'any':[np.mean(x[:,1]) for x in trans_probs]})\n",
    "prob_SEMs = pd.DataFrame({\"days\":extra_days, 'any':[stats.sem(x[:,1]) for x in trans_probs]})\n",
    "to_plot.sort_values(by=\"days\", inplace=True)\n",
    "prob_SEMs.sort_values(by=\"days\", inplace=True)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(to_plot[\"days\"]+23, to_plot[\"any\"], color=\"black\")\n",
    "plt.fill_between(to_plot[\"days\"]+23, to_plot[\"any\"]-prob_SEMs[\"any\"], to_plot[\"any\"]+prob_SEMs[\"any\"], color=\"black\", alpha=0.1)\n",
    "plt.ylabel(\"probability of passing on variant\", fontsize=14)\n",
    "plt.xlabel(\"infection length (days)\", fontsize=14)\n",
    "#plt.yscale(\"log\")\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\".pdf\", transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulations for Fig. 2B\n",
    "viral_load_kinetics = [1000, 1e3, 1e5, 1e5, 1e6, 1e6, 1e6, 1e7, 1e7, 1e7, 1e8, 1e8, 1e9, 1e9, 1e9, 1e9, 1e8, 1e8, 1e8, 1e8, 1e7, 1e7, 1e7, 1e7, 1e6, 1e6, 1e6, 1e6, 1e6, 1e6, 1e6, 1e6, 1e5, 1e5, 1e5, 1e5, 1e5, 1e5, 1e5, 1e5, 1e5, 1e5, 1e4, 1e4, 1e4, 1e3]\n",
    "viral_load_adj = np.array(viral_load_kinetics)/1000\n",
    "\n",
    "efficacies = np.arange(4)\n",
    "benefit = 0.2\n",
    "\n",
    "num_iter = 1000\n",
    "\n",
    "for eff in efficacies:\n",
    "    print(eff)\n",
    "    viral_load_treat = viral_load_adj/10**eff\n",
    "    viral_load_treat = viral_load_treat[viral_load_treat >= 1]\n",
    "    all_res = []\n",
    "    for i in range(num_iter):\n",
    "        all_res.append(simulate(viral_load_treat, None, benefit, 1, 1e-5, burst_size=1))\n",
    "    pickle.dump(all_res, open(\"./results/treatment_\"+str(eff)+\".p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting Fig. 2B\n",
    "efficacies = np.arange(4)\n",
    "\n",
    "means = []\n",
    "lowers = []\n",
    "uppers = []\n",
    "trans_probs = []\n",
    "for eff in efficacies:\n",
    "    data = pickle.load(open(\"./results/treatment_\"+str(eff)+\".p\", \"rb\" ))\n",
    "    mean, lower, upper = compute_fracs(data, log_data=False, CI=None, median=False)\n",
    "    means.append(mean)\n",
    "    lowers.append(lower)\n",
    "    uppers.append(upper)\n",
    "    trans_probs.append(transmit_probs(data))\n",
    "    \n",
    "to_plot = pd.DataFrame({\"eff\":efficacies, 'any':[np.mean(x[:,1]) for x in trans_probs]})\n",
    "prob_SEMs = pd.DataFrame({\"eff\":efficacies, 'any':[stats.sem(x[:,1]) for x in trans_probs]})\n",
    "to_plot.sort_values(by=\"eff\", inplace=True)\n",
    "prob_SEMs.sort_values(by=\"eff\", inplace=True)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(to_plot[\"eff\"], to_plot[\"any\"], color=\"black\")\n",
    "plt.fill_between(to_plot[\"eff\"], to_plot[\"any\"]-prob_SEMs[\"any\"], to_plot[\"any\"]+prob_SEMs[\"any\"], color=\"black\", alpha=0.1)\n",
    "plt.ylabel(\"probability of passing on variant\", fontsize=14)\n",
    "plt.xlabel(\"fold reduction in viral load\", fontsize=14)\n",
    "#plt.yscale(\"log\")\n",
    "plt.xticks(ticks=efficacies, labels=10**efficacies, fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\".pdf\", transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulations for Fig. 3- two mutation combination\n",
    "left_kinetics = [1000, 1e3, 1e5, 1e5, 1e6, 1e6, 1e6, 1e7, 1e7, 1e7, 1e8, 1e8]\n",
    "right_kinetics = [1e9, 1e9, 1e9, 1e9, 1e8, 1e8, 1e8, 1e8, 1e7, 1e7, 1e7, 1e7, 1e6, 1e6, 1e6, 1e6, 1e6, 1e6, 1e6, 1e6, 1e5, 1e5, 1e5, 1e5, 1e5, 1e5, 1e5, 1e5, 1e5, 1e5, 1e4, 1e4, 1e4, 1e3]\n",
    "extra_weeks = [0, 1, 2, 3, 4, 5, 10, 15]\n",
    "valley = 0.05\n",
    "benefit = 0.2\n",
    "\n",
    "num_iter = 1000\n",
    "\n",
    "for time in extra_weeks:\n",
    "    print(time)\n",
    "    all_res = []\n",
    "    new_viral_load = left_kinetics + [1e9]*(time*14) + right_kinetics\n",
    "    new_viral_load = np.array(new_viral_load)/1000\n",
    "    for i in range(num_iter):\n",
    "        all_res.append(simulate(new_viral_load, valley, benefit, 2, 1e-5, burst_size=1))\n",
    "    pickle.dump(all_res, open(\"./results/valley_long_\"+str(time)+\".p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulations for Fig. 3- three mutation combination\n",
    "left_kinetics = [1000, 1e3, 1e5, 1e5, 1e6, 1e6, 1e6, 1e7, 1e7, 1e7, 1e8, 1e8]\n",
    "right_kinetics = [1e9, 1e9, 1e9, 1e9, 1e8, 1e8, 1e8, 1e8, 1e7, 1e7, 1e7, 1e7, 1e6, 1e6, 1e6, 1e6, 1e6, 1e6, 1e6, 1e6, 1e5, 1e5, 1e5, 1e5, 1e5, 1e5, 1e5, 1e5, 1e5, 1e5, 1e4, 1e4, 1e4, 1e3]\n",
    "extra_weeks = [0, 1, 2, 3, 4, 5, 10, 15]\n",
    "valley = 0.05\n",
    "benefit = 0.2\n",
    "\n",
    "num_iter = 1000\n",
    "\n",
    "for time in extra_weeks:\n",
    "    print(time)\n",
    "    all_res = []\n",
    "    new_viral_load = left_kinetics + [1e9]*(time*14) + right_kinetics\n",
    "    new_viral_load = np.array(new_viral_load)/1000\n",
    "    for i in range(num_iter):\n",
    "        all_res.append(simulate(new_viral_load, valley, benefit, 3, 1e-5, burst_size=1))\n",
    "    pickle.dump(all_res, open(\"./results/valley_long_3_\"+str(time)+\".p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting Fig. 3B\n",
    "\n",
    "extra_weeks = [0, 1, 2, 3, 4, 5, 10, 15]\n",
    "\n",
    "means = []\n",
    "lowers = []\n",
    "uppers = []\n",
    "trans_probs = []\n",
    "for week in extra_weeks:\n",
    "    data = pickle.load(open(\"./results/valley_long_\"+str(week)+\".p\", \"rb\" ))\n",
    "    mean, lower, upper = compute_fracs(data, log_data=False, CI=None, median=False)\n",
    "    means.append(mean)\n",
    "    lowers.append(lower)\n",
    "    uppers.append(upper)\n",
    "    trans_probs.append(transmit_probs(data, num_trans=10))\n",
    "    \n",
    "to_plot_hold = pd.DataFrame({\"week\":extra_weeks, 'any':[np.mean(x[:,2]) for x in trans_probs]})\n",
    "SEMS_hold = pd.DataFrame({\"week\":extra_weeks, 'any':[stats.sem(x[:,2]) for x in trans_probs]})\n",
    "to_plot_hold.sort_values(by=\"week\", inplace=True)\n",
    "SEMS_hold.sort_values(by=\"week\", inplace=True)\n",
    "uppers_hold = uppers\n",
    "lowers_hold = lowers\n",
    "means_hold = means\n",
    "\n",
    "means = []\n",
    "lowers = []\n",
    "uppers = []\n",
    "trans_probs = []\n",
    "for week in extra_weeks:\n",
    "    data = pickle.load(open(\"./results/valley_long_3_\"+str(week)+\".p\", \"rb\" ))\n",
    "    mean, lower, upper = compute_fracs(data, log_data=False, CI=None, median=False)\n",
    "    means.append(mean)\n",
    "    lowers.append(lower)\n",
    "    uppers.append(upper)\n",
    "    trans_probs.append(transmit_probs(data, num_trans=10))\n",
    "    \n",
    "to_plot = pd.DataFrame({\"week\":extra_weeks, 'any':[np.mean(x[:,3]) for x in trans_probs]})\n",
    "prob_SEMs = pd.DataFrame({\"week\":extra_weeks, 'any':[stats.sem(x[:,3]) for x in trans_probs]})\n",
    "to_plot.sort_values(by=\"week\", inplace=True)\n",
    "prob_SEMs.sort_values(by=\"week\", inplace=True)\n",
    "\n",
    "plt.figure()\n",
    "mut_index = 3\n",
    "i = 7\n",
    "xplot = np.arange(len(means[i][:,mut_index]))/(2*7)\n",
    "plt.plot(xplot, means[i][:,mut_index], color=\"maroon\")\n",
    "plt.fill_between(xplot, lowers[i][:,mut_index], uppers[i][:,mut_index], color=\"maroon\", alpha=0.1)\n",
    "\n",
    "mut_index = 2\n",
    "i = 7\n",
    "plt.plot(xplot, means_hold[i][:,mut_index], color=\"blue\")\n",
    "plt.fill_between(xplot, lowers_hold[i][:,mut_index], uppers_hold[i][:,mut_index], color=\"blue\", alpha=0.1)\n",
    "    \n",
    "#plt.yscale(\"log\")\n",
    "plt.ylabel(\"mean intrahost\\nfrequency of variant\", fontsize=14)\n",
    "plt.xlabel(\"weeks since infection started\", fontsize=14)\n",
    "plt.xticks(ticks = [0,2,4,6,8,10,12,14,16,18], fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\".pdf\", transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting Fig. 3C\n",
    "plt.figure()\n",
    "plt.plot(to_plot_hold[\"week\"]+3, to_plot_hold[\"any\"], color=\"blue\")\n",
    "plt.fill_between(to_plot_hold[\"week\"]+3, to_plot_hold[\"any\"]-SEMS_hold[\"any\"], to_plot_hold[\"any\"]+SEMS_hold[\"any\"], color=\"blue\", alpha=0.1)\n",
    "\n",
    "plt.plot(to_plot[\"week\"]+3, to_plot[\"any\"], color=\"maroon\")\n",
    "plt.fill_between(to_plot[\"week\"]+3, to_plot[\"any\"]-prob_SEMs[\"any\"], to_plot[\"any\"]+prob_SEMs[\"any\"], color=\"maroon\", alpha=0.1)\n",
    "plt.ylabel(\"probability of passing on variant\", fontsize=14)\n",
    "plt.xlabel(\"infection length (wks)\", fontsize=14)\n",
    "plt.yscale(\"log\")\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.ylim(1e-10, 2e-1)\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\".pdf\", transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting Fig. 3D\n",
    "lam = 1.5\n",
    "def find_pext(x):\n",
    "    return(1-np.exp(-lam*x) - x)\n",
    "\n",
    "N = 5e4\n",
    "p_surv = scipy.optimize.broyden1(find_pext, 0.1, f_tol=1e-14)\n",
    "long_nvar_2mut = np.sum(to_plot_hold[\"any\"][1:] * long_dist * p_surv*N)\n",
    "short_nvar_2mut = to_plot_hold[\"any\"][0]\n",
    "\n",
    "frac_long = [0.0001, 0.001, 0.01, 0.05]\n",
    "combined_nvar = [short_nvar_2mut*(1-p) + long_nvar_2mut*p for p in frac_long]\n",
    "label_percent = [str(x)+\"%\" for x in np.array(frac_long)*100]\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(x=range(len(frac_long)), height=combined_nvar, fill=\"blue\")\n",
    "plt.xticks(ticks=range(len(frac_long)), labels=label_percent, fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.ylabel(\"number of infections/day with\\nnew two-mutation combination\", fontsize=14)\n",
    "plt.xlabel(\"long-term viral shedder frequency in population\", fontsize=14)\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\".eps\", transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling data from previous simulations and plotting\n",
    "# all previous simulations for the two mutation combination must be run prior to this\n",
    "\n",
    "extra_weeks = [0, 1, 2, 3, 4, 5, 10, 15]\n",
    "\n",
    "means = []\n",
    "lowers = []\n",
    "uppers = []\n",
    "trans_probs = []\n",
    "for week in extra_weeks:\n",
    "    data = pickle.load(open(\"./results/valley_long_\"+str(week)+\".p\", \"rb\" ))\n",
    "    mean, lower, upper = compute_fracs(data, log_data=False, CI=None, median=False)\n",
    "    means.append(mean)\n",
    "    lowers.append(lower)\n",
    "    uppers.append(upper)\n",
    "    trans_probs.append(transmit_probs(data, num_trans=10))\n",
    "    \n",
    "to_plot = pd.DataFrame({\"week\":extra_weeks, 'any':[np.mean(x[:,2]) for x in trans_probs]})\n",
    "prob_SEMs = pd.DataFrame({\"week\":extra_weeks, 'any':[stats.sem(x[:,2]) for x in trans_probs]})\n",
    "to_plot.sort_values(by=\"week\", inplace=True)\n",
    "prob_SEMs.sort_values(by=\"week\", inplace=True)\n",
    "\n",
    "N = 5e4\n",
    "import scipy.optimize\n",
    "lam = 1.5\n",
    "def find_pext(x):\n",
    "    return(1-np.exp(-lam*x) - x)\n",
    "\n",
    "p_surv = scipy.optimize.broyden1(find_pext, 0.1, f_tol=1e-14)\n",
    "long_nvar_2mut = np.sum(to_plot[\"any\"][1:] * long_dist * p_surv*N)\n",
    "short_nvar_2mut = to_plot[\"any\"][0]\n",
    "\n",
    "frac_long = [0.001, 0.001*0.1]\n",
    "combined_nvar = [short_nvar_2mut*(1-p) + long_nvar_2mut*p for p in frac_long]\n",
    "\n",
    "# lower viral load\n",
    "extra_weeks = [0, 1, 2, 3, 4, 5, 10, 15]\n",
    "\n",
    "means = []\n",
    "lowers = []\n",
    "uppers = []\n",
    "trans_probs = []\n",
    "for week in extra_weeks:\n",
    "    data = pickle.load(open(\"./results/treated_valley_long_\"+str(week)+\".p\", \"rb\" ))\n",
    "    mean, lower, upper = compute_fracs(data, log_data=False, CI=None, median=False)\n",
    "    means.append(mean)\n",
    "    lowers.append(lower)\n",
    "    uppers.append(upper)\n",
    "    trans_probs.append(transmit_probs(data, num_trans=10))\n",
    "    \n",
    "to_plot = pd.DataFrame({\"week\":extra_weeks, 'any':[np.mean(x[:,2]) for x in trans_probs]})\n",
    "prob_SEMs = pd.DataFrame({\"week\":extra_weeks, 'any':[stats.sem(x[:,2]) for x in trans_probs]})\n",
    "to_plot.sort_values(by=\"week\", inplace=True)\n",
    "prob_SEMs.sort_values(by=\"week\", inplace=True)\n",
    "\n",
    "long_nvar_2mut = np.sum(to_plot[\"any\"][1:] * long_dist * p_surv*N)\n",
    "short_nvar_2mut = to_plot[\"any\"][0]\n",
    "\n",
    "p = 0.001\n",
    "combined_nvar.append(short_nvar_2mut*(1-p) + long_nvar_2mut*p)\n",
    "\n",
    "#less transmitted\n",
    "means = []\n",
    "lowers = []\n",
    "uppers = []\n",
    "trans_probs = []\n",
    "for week in extra_weeks:\n",
    "    data = pickle.load(open(\"./results/valley_long_\"+str(week)+\".p\", \"rb\" ))\n",
    "    mean, lower, upper = compute_fracs(data, log_data=False, CI=None, median=False)\n",
    "    means.append(mean)\n",
    "    lowers.append(lower)\n",
    "    uppers.append(upper)\n",
    "    trans_probs.append(transmit_probs(data, num_trans=1))\n",
    "    \n",
    "to_plot = pd.DataFrame({\"week\":extra_weeks, 'any':[np.mean(x[:,2]) for x in trans_probs]})\n",
    "prob_SEMs = pd.DataFrame({\"week\":extra_weeks, 'any':[stats.sem(x[:,2]) for x in trans_probs]})\n",
    "to_plot.sort_values(by=\"week\", inplace=True)\n",
    "prob_SEMs.sort_values(by=\"week\", inplace=True)\n",
    "\n",
    "long_nvar_2mut = np.sum(to_plot[\"any\"][1:] * long_dist * p_surv*N)\n",
    "short_nvar_2mut = to_plot[\"any\"][0]\n",
    "\n",
    "p = 0.001\n",
    "combined_nvar.append(short_nvar_2mut*(1-p) + long_nvar_2mut*p)\n",
    "\n",
    "#lower R0\n",
    "means = []\n",
    "lowers = []\n",
    "uppers = []\n",
    "trans_probs = []\n",
    "for week in extra_weeks:\n",
    "    data = pickle.load(open(\"./results/valley_long_\"+str(week)+\".p\", \"rb\" ))\n",
    "    mean, lower, upper = compute_fracs(data, log_data=False, CI=None, median=False)\n",
    "    means.append(mean)\n",
    "    lowers.append(lower)\n",
    "    uppers.append(upper)\n",
    "    trans_probs.append(transmit_probs(data, num_trans=8))\n",
    "    \n",
    "to_plot = pd.DataFrame({\"week\":extra_weeks, 'any':[np.mean(x[:,2]) for x in trans_probs]})\n",
    "prob_SEMs = pd.DataFrame({\"week\":extra_weeks, 'any':[stats.sem(x[:,2]) for x in trans_probs]})\n",
    "to_plot.sort_values(by=\"week\", inplace=True)\n",
    "prob_SEMs.sort_values(by=\"week\", inplace=True)\n",
    "\n",
    "N = 5e4\n",
    "import scipy.optimize\n",
    "lam = 1.05\n",
    "def find_pext(x):\n",
    "    return(1-np.exp(-lam*x) - x)\n",
    "\n",
    "p_surv = scipy.optimize.broyden1(find_pext, 0.1, f_tol=1e-14)\n",
    "long_nvar_2mut = np.sum(to_plot[\"any\"][1:] * long_dist * p_surv*N)\n",
    "short_nvar_2mut = to_plot[\"any\"][0]\n",
    "\n",
    "combined_nvar.append(short_nvar_2mut*(1-p) + long_nvar_2mut*p)\n",
    "\n",
    "plt.figure(figsize=(9,6))\n",
    "treatment_ticks = [\"control\", \"fewer long\\ninfections\", \"reduced\\nviral load\", \"fewer virions\\ntransmitted\", \"reduced\\ntransmissibilty\"]\n",
    "plt.bar(treatment_ticks, combined_nvar, width=0.6, color=[\"lightgrey\", \"cornflowerblue\", \"cornflowerblue\", \"mistyrose\", \"tomato\"])\n",
    "for i in range(len(combined_nvar)):\n",
    "    plt.text(treatment_ticks[i], combined_nvar[i]+0.05, str(round(combined_nvar[i],2)), fontsize=14, ha=\"center\")\n",
    "\n",
    "plt.ylabel(\"number of infections/day with\\nnew two-mutation combination\", fontsize=14)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\".eps\", transparent=True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
